# Qanooni â€“ Legal Assistant Chatbot

Qanooni is a Streamlit-based legal assistant chatbot designed to help users navigate and query the Saudi Labor Law ("Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù…Ù„"). It leverages a document ingestion pipeline, a retrieval engine, and a user-friendly chat interface to deliver accurate, context-aware answers.

---

## ðŸ§© Problem & Solution

### The Problem
Accessing and understanding the Saudi Labor Law is difficult â€” especially for individuals â€” due to complex language, scattered sources, and lack of accessible legal tools.

### Our Solution
**Qanooni** simplifies legal access by offering:
- Natural-language Q&A grounded in official law
- Smart retrieval using semantic search
- Clear references to specific articles
- Easy access through a user-friendly chat interface
- A focused scope on Saudi Labor Law for high accuracy

---

## ðŸš€ Features

- **Intuitive Chat Interface:** Natural-language Q\&A over Labor Law chapters and articles.
- **Document Ingestion:** Scripts to parse and load articles & clauses into the knowledge base.
- **Retrieval Engine:** Fast search and retrieval of relevant legal provisions.
- **Modular Structure:** Clear separation between client UI, data processing, and backend logic.


---

## ðŸ§  Why Qanooni?

Qanooni isnâ€™t just another legal chatbot â€” itâ€™s built with precision and depth in mind:

1. **Direct Legal References:** All responses are grounded in the official Saudi Labor Law, with clear referencing to the specific article or clause.
2. **Intelligent Retrieval:** We use **cosine similarity** over semantic embeddings to retrieve the most relevant law text, ensuring contextual accuracy.
3. **Legal Reasoning:** The system draws logical links between user queries and legal provisions, enabling more insightful responses beyond keyword matching.
4. **Focused Domain Expertise:** By specializing only in **Saudi Labor Law**, we ensure deep, high-fidelity answers â€” unlike general legal bots that risk ambiguity across multiple fields.


---

## ðŸ› ï¸ Prerequisites

- **Python 3.9+** installed on your machine
- **pip** for package management
- (Optional) A virtual environment tool such as venv or conda

---

## âš¡ Installation

1. **Clone the repository**

   
bash
   git clone https://github.com/your-org/qanooni.git
   cd qanooni


2. **Install dependencies**

   
bash
   pip install -r requirements.txt


3. **Environment variables**

   - Create a .env file in the root (or in env/) with any required keys, for example:

     
dotenv
     OPENAI_API_KEY=your_openai_api_key
     MONGO_URI=your_mongodb_connection_string


---

## ðŸ“‚ Project Structure

plaintext
qanooni/
â”œâ”€â”€ client/                  # Streamlit front-end application
â”‚   â”œâ”€â”€ app.py               # Main entry point for the web app
â”‚   â”œâ”€â”€ pages/               # Additional Streamlit pages
â”‚   â”‚   â””â”€â”€ chat_app.py      # Chat interface page
â”‚   â”œâ”€â”€ components/          # Reusable UI components (buttons, cards, etc.)
â”‚   â””â”€â”€ .gitignore           # Ignore rules for the client folder
â”‚
â”œâ”€â”€ server/                  # (Optional) Back-end APIs or microservices
â”‚   â””â”€â”€ ...                  # (Provide details if applicable)
â”‚
â”œâ”€â”€ data/                    # Data ingestion & retrieval logic
â”‚   â”œâ”€â”€ ingest_articles.py   # Script to parse and load articles into DB
â”‚   â”œâ”€â”€ ingest_clauses.py    # Script to parse and load clauses into DB
â”‚   â”œâ”€â”€ laws.py              # Loader for raw law documents
â”‚   â”œâ”€â”€ retriever.py         # Search and retrieval engine implementation
â”‚   â”œâ”€â”€ conversation_handler.py  # Orchestrates Q&A pipeline
â”‚   â””â”€â”€ sql.sql              # Database schema (if using SQL storage)
â”‚
â”œâ”€â”€ styles/                  # Static assets & styling
â”‚   â”œâ”€â”€ logo.png             # Project logo shown in the header
â”‚   â””â”€â”€ .gitignore
â”‚
â”œâ”€â”€ env/                     # Environment file templates / examples
â”‚   â””â”€â”€ .env.example         # Example environment variables
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # This documentation file


---

## â–¶ï¸ Usage

### 1. Run the Streamlit App

From the project root, execute:

bash
streamlit run client/app.py


This will launch the web UI at http://localhost:8501 by default. Use the sidebar or top navigation to switch between pages (e.g., the chat interface chat_app.py).

### 2. Data Ingestion

If you update the source PDFs or raw law files, re-run the ingestion scripts:

bash
python data/ingest_articles.py
python data/ingest_clauses.py


This populates or refreshes your database with the latest content.

### 3. Customization

- **Environment Variables:** Adjust keys in your .env file.
- **UI Components:** Modify or extend in client/components/.
- **Retrieval Logic:** Tweak search settings in data/retriever.py.

---

## ðŸ“– Manual Structure

The Labor Law document follows a structured, book-like format:

1. **Articles** (Ù…Ø§Ø¯Ø©)
   Numbered entries within each chapter. Each Article has:

   - A **title**
   - The **full text** of the provision

2. **Clauses**
   Sub-points inside an Article, labeled (a), (b), (c), â€¦ to break down complex rules.

3. **Appendices**
   Supplementary tables or definitions (e.g., salary scales, leave entitlements) that some Articles reference.

When you reference or quote the law in your README or other docs, use these headings and numbering conventions to match the official structure.

---

# ðŸ” Supabase Embeddings & Retrieval Overview

Supabase provides a PostgreSQL-based stack with support for **vector embeddings**, search, and retrieval using the `pgvector` extension. This allows developers to build semantic search systems using their own embedding models and integrate it directly with the database.

---

## ðŸ§  How Supabase Handles Embeddings

### 1. **Embedding Generation**
- Supabase does **not** generate embeddings itself â€” you need to use external models such as:
  - OpenAI (`text-embedding-ada-002`)
  - Hugging Face Transformers
  - Cohere, etc.

You run embedding generation *client-side* or in your server, and then store the resulting vectors in a `vector` column in PostgreSQL.

### 2. **Storing in PostgreSQL (with `pgvector`)**
- Supabase enables the `pgvector` extension, which allows storing and querying high-dimensional vectors.
- You define a column of type `vector(1536)` (e.g., for OpenAI embeddings).
  
Example:
```sql
CREATE TABLE law_articles (
  id serial PRIMARY KEY,
  title text,
  content text,
  embedding vector(1536)
);
```

## ðŸ“ Contributing

Contributions are welcome! Please open issues or pull requests for any bugs, feature requests, or improvements. Follow the standard GitHub workflow:

1. Fork the repository
2. Create a feature branch (git checkout -b feature/YourFeature)
3. Commit your changes (git commit -m "Add some feature")
4. Push to your branch (git push origin feature/YourFeature)
5. Open a Pull Request

---

## ðŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

> _Questions? Feel free to ask for any additional files or clarifications!_
